# llm_worker/worker.py
# Small FastAPI service that runs in its own venv and uses google-genai to generate text.
# It writes a .docx file into the backend TMP_DIR and returns JSON { file_path, text }.
import os
import uuid
from pathlib import Path
from typing import Optional, Dict, Any
from fastapi import FastAPI, HTTPException, Header, Request
from pydantic import BaseModel
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("llm_worker")

# Paths (same TMP_DIR as backend)
TMP_DIR = os.environ.get("BACKEND_TMP_DIR", "/Users/naveen/ai-docs-platform/backend/tmp")
Path(TMP_DIR).mkdir(parents=True, exist_ok=True)

# Gemini / Google GenAI config
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
GEMINI_MODEL = os.environ.get("GEMINI_MODEL", "gemini-2.5-flash")
WORKER_TOKEN = os.environ.get("WORKER_TOKEN")  # optional simple auth

app = FastAPI(title="LLM Worker (Gemini)")

# Try import google-genai lazily
try:
    from google import genai
    GENAI_AVAILABLE = True
except Exception as e:
    logger.warning("google-genai SDK not available in this worker venv: %s", e)
    GENAI_AVAILABLE = False

# python-docx for writing docx
try:
    from docx import Document
    DOCX_AVAILABLE = True
except Exception:
    DOCX_AVAILABLE = False

class GenRequest(BaseModel):
    project_id: str
    prompt: Optional[str] = None
    sections: Optional[list] = None
    # Optional: pass an internal request id or metadata
    metadata: Optional[Dict[str, Any]] = None

@app.get("/health")
def health():
    return {"status": "ok", "genai": GENAI_AVAILABLE, "docx": DOCX_AVAILABLE}

def _create_docx_from_text(project_id: str, text: str) -> str:
    fname = f"{project_id}-{int(uuid.uuid4().int>>64)}.docx"
    out_path = os.path.join(TMP_DIR, fname)
    try:
        if DOCX_AVAILABLE:
            doc = Document()
            # simple: heading + paragraphs split by double newlines
            doc.add_heading(project_id, level=1)
            for para in [p.strip() for p in text.split("\n\n") if p.strip()]:
                doc.add_paragraph(para)
            doc.add_paragraph("\n\n---\nGenerated by llm_worker.")
            doc.save(out_path)
        else:
            # fallback: write text file with .docx extension
            with open(out_path, "w") as f:
                f.write(text)
    except Exception as e:
        logger.exception("Failed to write docx: %s", e)
        raise
    return out_path

def _call_gemini(prompt: str) -> str:
    """
    Call google-genai SDK. Returns generated text or raises on error.
    """
    if not GENAI_AVAILABLE:
        raise RuntimeError("google-genai SDK not installed in worker venv")
    if not GEMINI_API_KEY:
        raise RuntimeError("GEMINI_API_KEY not set in worker env")

    client = genai.Client(api_key=GEMINI_API_KEY)
    model = GEMINI_MODEL
    logger.info("Calling Gemini model=%s", model)

    # Use the SDK generate_content API
    # Note: SDK versions differ; handle common shapes
    resp = client.models.generate_content(model=model, contents=prompt)
    # Try to extract text in several ways:
    text = None
    if hasattr(resp, "text"):
        text = resp.text
    else:
        try:
            text = resp["text"]
        except Exception:
            text = str(resp)
    return text

@app.post("/generate")
async def generate(req: GenRequest, authorization: Optional[str] = Header(None)):
    # Optional simple auth: if WORKER_TOKEN is set, require header Authorization: Bearer <WORKER_TOKEN>
    if WORKER_TOKEN:
        if not authorization or not authorization.startswith("Bearer "):
            raise HTTPException(status_code=401, detail="Missing worker auth")
        token = authorization.split(" ", 1)[1].strip()
        if token != WORKER_TOKEN:
            raise HTTPException(status_code=403, detail="Invalid worker token")

    project_id = req.project_id
    # Build prompt if not supplied
    prompt = req.prompt
    if not prompt:
        parts = []
        if req.sections:
            for s in req.sections:
                t = s.get("title", "")
                c = s.get("content", "")
                parts.append(f"### {t}\n{c}")
        prompt = "Create a one-page document based on the following sections:\n\n" + "\n\n".join(parts)

    logger.info("Worker received generate request for project %s", project_id)

    # Try calling Gemini
    generated_text = None
    try:
        generated_text = _call_gemini(prompt)
    except Exception as e:
        logger.exception("Gemini call failed, falling back to local synthesis: %s", e)
        # Fallback: build a simple combined text from sections
        lines = [project_id, ""]
        if req.sections:
            for s in req.sections:
                lines.append(s.get("title",""))
                lines.append(s.get("content",""))
                lines.append("")
        lines.append("\n[LLM fallback after error]")
        generated_text = "\n".join(lines)

    # Write a docx and return file path
    try:
        out_path = _create_docx_from_text(project_id, generated_text)
    except Exception as e:
        logger.exception("Failed to write output file: %s", e)
        raise HTTPException(status_code=500, detail="Failed to write output file")

    return {"status": "ok", "file_path": out_path, "text_snippet": generated_text[:1000]}
